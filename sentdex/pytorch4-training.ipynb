{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "49375755-b5d4-4600-be65-be6a44ee538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO building neural network\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7e4c68d4-68b1-41aa-9863-31135b77f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3134620c-7a03-4448-8764-15dc2ef1456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([64, 784])\n",
      "fc1.bias \t torch.Size([64])\n",
      "fc2.weight \t torch.Size([64, 64])\n",
      "fc2.bias \t torch.Size([64])\n",
      "fc3.weight \t torch.Size([64, 64])\n",
      "fc3.bias \t torch.Size([64])\n",
      "fc4.weight \t torch.Size([10, 64])\n",
      "fc4.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n",
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "# Initialize model\n",
    "net = Net()\n",
    "\n",
    "# Initialize optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e45c5c67-6bd0-40e4-939a-848d8685e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002e-05, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d6a1935f-a095-4138-bc56-db30d32f140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.991\n"
     ]
    }
   ],
   "source": [
    "# check how good is network\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e7af0c12-d915-439d-a280-943e9dee1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "import time\n",
    "PATH = f\"MNIST_trained_model-{EPOCHS}_epochs-{int(time.time())}\"\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "92d04d40-b8b8-4ba9-b6ff-a1f96a409127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "MODEL_NAME = \"MNIST_trained_model-10_epochs-1718478650\"\n",
    "net.load_state_dict(torch.load(MODEL_NAME))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6f3ab926-fd43-4af2-9fca-9128e164658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "43bef8c7-cbc2-48e9-86ad-600a96772cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1, 28*28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f8479846-1b6b-4d27-a5f2-7fe560e4a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor: tensor([[ -0.1920, -12.0579,  -2.2811,  -2.7866,  -5.6787, -12.7267, -15.4410,\n",
      "          -7.4496,  -6.6471,  -5.1897]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[ -0.1919879 -12.057859   -2.2811012  -2.786586   -5.6786537 -12.726727\n",
      "  -15.441033   -7.449615   -6.6471076  -5.189708 ]]\n",
      "0: Predicted class index: 0\n",
      "\n",
      "Output tensor: tensor([[-22.4134,  -0.8600,  -0.5572, -12.5345,  -9.6482, -19.0154, -16.7349,\n",
      "          -5.5337, -14.3450, -17.0296]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-22.413433    -0.86003834  -0.55715954 -12.534548    -9.648236\n",
      "  -19.015423   -16.734943    -5.533681   -14.345042   -17.029644  ]]\n",
      "1: Predicted class index: 2\n",
      "\n",
      "Output tensor: tensor([[-43.0574, -24.5327,   0.0000, -21.4490, -30.9988, -49.5364, -50.5423,\n",
      "         -26.9539, -37.9228, -50.7244]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-43.057426 -24.532717   0.       -21.449028 -30.998838 -49.536354\n",
      "  -50.542267 -26.953863 -37.9228   -50.724403]]\n",
      "2: Predicted class index: 2\n",
      "\n",
      "Output tensor: tensor([[-12.5909, -12.3793,  -2.3555,  -0.1002, -19.2190,  -8.1249, -21.0893,\n",
      "         -10.7305,  -8.5159, -19.2322]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-12.590919   -12.379347    -2.3554516   -0.10023645 -19.218967\n",
      "   -8.124902   -21.089258   -10.73048     -8.5158615  -19.23218   ]]\n",
      "3: Predicted class index: 3\n",
      "\n",
      "Output tensor: tensor([[-2.6429e+01, -2.3240e+01, -1.3020e+01, -3.6100e+01, -3.2186e-06,\n",
      "         -2.7850e+01, -2.3231e+01, -1.3871e+01, -2.3297e+01, -2.2505e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-2.6428967e+01 -2.3240246e+01 -1.3019649e+01 -3.6099953e+01\n",
      "  -3.2186456e-06 -2.7850433e+01 -2.3231241e+01 -1.3870612e+01\n",
      "  -2.3297220e+01 -2.2504837e+01]]\n",
      "4: Predicted class index: 4\n",
      "\n",
      "Output tensor: tensor([[-11.8219,  -8.5030,  -6.0499,  -6.4485, -17.1049,  -0.0536,  -5.2208,\n",
      "         -17.9508,  -3.1543, -21.9479]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-11.821893    -8.50296     -6.049932    -6.4485407  -17.104885\n",
      "   -0.05363506  -5.2208257  -17.95075     -3.1543036  -21.94789   ]]\n",
      "5: Predicted class index: 5\n",
      "\n",
      "Output tensor: tensor([[-23.3410, -12.5287,  -7.3362,  -1.7370, -20.4122,  -3.3570, -18.0036,\n",
      "         -18.2097,  -0.2377, -19.5372]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-23.341      -12.528701    -7.3361607   -1.736957   -20.412205\n",
      "   -3.357008   -18.003632   -18.209694    -0.23768611 -19.537218  ]]\n",
      "6: Predicted class index: 8\n",
      "\n",
      "Output tensor: tensor([[-1.4176e+01, -9.6291e+00, -5.7325e+00, -1.7420e-02, -1.2563e+01,\n",
      "         -9.5009e+00, -2.2002e+01, -4.7504e+00, -5.2537e+00, -1.1597e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-1.4176332e+01 -9.6291351e+00 -5.7324533e+00 -1.7420262e-02\n",
      "  -1.2563271e+01 -9.5009441e+00 -2.2001888e+01 -4.7503972e+00\n",
      "  -5.2537246e+00 -1.1597305e+01]]\n",
      "7: Predicted class index: 3\n",
      "\n",
      "Output tensor: tensor([[-1.5651e+01, -1.3095e+01, -1.6037e+01, -1.4139e+01, -2.6195e+01,\n",
      "         -1.9126e+01, -2.5491e+01, -2.7474e+01, -2.9802e-06, -1.9510e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-1.5650985e+01 -1.3095052e+01 -1.6037201e+01 -1.4139455e+01\n",
      "  -2.6194773e+01 -1.9126423e+01 -2.5490965e+01 -2.7474239e+01\n",
      "  -2.9802277e-06 -1.9510384e+01]]\n",
      "8: Predicted class index: 8\n",
      "\n",
      "Output tensor: tensor([[-1.0990e+01, -1.3805e+01, -1.3980e+01, -5.9270e+00, -8.9379e+00,\n",
      "         -7.9386e+00, -2.3051e+01, -7.2337e+00, -1.1104e+01, -3.9178e-03]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted probability distribution: [[-1.0990176e+01 -1.3804950e+01 -1.3979957e+01 -5.9270449e+00\n",
      "  -8.9378567e+00 -7.9385920e+00 -2.3051289e+01 -7.2336569e+00\n",
      "  -1.1104095e+01 -3.9177584e-03]]\n",
      "9: Predicted class index: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# recognize custom made digits\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_number = 0\n",
    "while os.path.isfile(f\"digits/digit{image_number}.png\"):\n",
    "    try:\n",
    "        # Load and prepare the image\n",
    "        img = cv2.imread(f\"digits/digit{image_number}.png\")[:,:,0]\n",
    "        \n",
    "        # Resizing to prevent misshaped digits\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "\n",
    "        # Perform thresholding to binarize the image\n",
    "        #_, img = cv2.threshold(img, thresh=128, maxval=255, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "        img = np.invert(img)\n",
    "        # Convert the prepared image to a PyTorch Tensor\n",
    "        input_tensor = torch.from_numpy(img).float() # convert the data type to float\n",
    "        input_tensor = input_tensor.reshape(-1, 28 * 28)/ 255.0 # faltten tensor into 1D\n",
    "\n",
    "        #print(input_tensor[0])\n",
    "        # Feed the input Tensor to the network and display the prediction\n",
    "        output = net(input_tensor)\n",
    "        print(f\"Output tensor: {output}\")\n",
    "        pred_probs = output.detach().numpy()\n",
    "        pred_class = np.argmax(pred_probs)\n",
    "        print(f\"Predicted probability distribution: {pred_probs}\")\n",
    "        print(f\"{image_number}: Predicted class index: {pred_class}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    image_number += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fd5e5925-4406-472d-ad37-8022529393f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(input_tensor[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7b89cf94-8879-412e-b08f-b44664b7573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.2196, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.2549, 0.3725, 0.2784, 0.4118, 0.5333, 0.4824,\n",
      "        0.4706, 0.5255, 0.5020, 0.5725, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.3059, 0.4588, 0.4824, 0.5686, 0.6471,\n",
      "        0.5922, 0.5333, 0.5608, 0.6000, 0.6392, 0.6353, 0.5216, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.5216, 0.5490, 0.5961, 0.5725,\n",
      "        0.5608, 0.5373, 0.4667, 0.4824, 0.6039, 0.7922, 0.7608, 0.6157, 0.4039,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.6000, 0.5412, 0.5059,\n",
      "        0.3373, 0.4824, 0.4000, 0.2431, 0.0000, 0.2471, 0.5922, 0.6863, 0.7569,\n",
      "        0.6980, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.5137, 0.4902,\n",
      "        0.3569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.6314,\n",
      "        0.7294, 0.6588, 0.4510, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6627, 0.5882,\n",
      "        0.4627, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.4118, 0.3412,\n",
      "        0.5451, 0.6196, 0.6157, 0.4431, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4863, 0.5843,\n",
      "        0.6471, 0.6275, 0.2667, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.5608,\n",
      "        0.5804, 0.7137, 0.5804, 0.5686, 0.6353, 0.4392, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4314, 0.5294, 0.5686, 0.3647, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412,\n",
      "        0.6706, 0.5882, 0.4588, 0.5412, 0.5373, 0.6314, 0.5137, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4000, 0.5686, 0.5608, 0.5373, 0.1373, 0.0000, 0.0000, 0.4392,\n",
      "        0.4588, 0.5804, 0.6706, 0.5569, 0.5137, 0.5490, 0.6000, 0.4824, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4510, 0.5647, 0.5412, 0.6353, 0.5961, 0.4902,\n",
      "        0.5490, 0.5608, 0.5333, 0.5216, 0.0000, 0.3294, 0.5059, 0.5255, 0.4588,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.2471, 0.5020, 0.6353, 0.6510, 0.5686,\n",
      "        0.5333, 0.6078, 0.6353, 0.5059, 0.0353, 0.0000, 0.2549, 0.5569, 0.5725,\n",
      "        0.5176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.4118, 0.5294,\n",
      "        0.4549, 0.4745, 0.4667, 0.3922, 0.2863, 0.0000, 0.0314, 0.4941, 0.6157,\n",
      "        0.5843, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.4353,\n",
      "        0.5961, 0.6941, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.5216,\n",
      "        0.5725, 0.5765, 0.6510, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.4275,\n",
      "        0.5843, 0.6314, 0.5255, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.5804,\n",
      "        0.5451, 0.6235, 0.5843, 0.4196, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.6471,\n",
      "        0.7059, 0.5647, 0.5490, 0.4902, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5333,\n",
      "        0.5412, 0.6431, 0.6000, 0.3686, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.5608, 0.5804, 0.6000, 0.4902, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.4706, 0.3608, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5dc0aa4f-baae-4a01-abb9-d09d5a941923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745,\n",
      "          0.9961, 0.9529, 0.3255, 0.2196, 0.0510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0157, 0.2196, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.7137, 0.6627, 0.6510, 0.5294,\n",
      "          0.8314, 0.9922, 0.8431, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314,\n",
      "          0.7922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020,\n",
      "          0.9529, 0.9373, 0.5216, 0.5843, 0.9176, 0.9137, 0.9137, 0.9176,\n",
      "          0.9137, 0.9373, 0.9961, 0.9922, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039,\n",
      "          0.9922, 0.8745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3922, 0.9961, 0.7765, 0.0235, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
      "          0.7137, 0.9843, 0.4471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0314, 0.8314, 0.9922, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4039, 0.9922, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0627, 0.9922, 0.9608, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2980, 0.8824, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6431, 0.9922, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2980, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
      "          0.9569, 0.9922, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0078, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392,\n",
      "          0.9922, 0.8314, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
      "          0.9922, 0.5569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1059, 0.8588,\n",
      "          0.9804, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.9922,\n",
      "          0.9333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5176, 0.9922,\n",
      "          0.8275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.8196, 0.9961,\n",
      "          0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.9922, 0.9922,\n",
      "          0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4078, 0.9922, 0.7765,\n",
      "          0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5843, 0.9922, 0.7608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5882, 0.9922, 0.7608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5843, 0.9922, 0.7569,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd59c8-dcaf-45f2-8e4f-3a779d4de184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
